--- 
layout: post
title: 机器学习笔记
category: 机器学习
tags: 
keywords：决策树 机器学习
description: 
--- 

# 决策树
## 划分选择
- 信息增益
- 增益率
- 基尼指数

## 剪枝处理
剪枝是决策树算法对付“过拟合”的主要手段，通过主动去掉一些分支来降低过拟合的风险。根据泛化性能是否提升来判断和评估要不要留下这个分支。

那么，如何判断决策树的泛化性能是否提升呢？可以采用“留出法”（一种性能评估方法），即预留一部分数据用作“验证集”来进行性能评估。

- 预剪枝

是否应该进行这个划分？预剪枝要对划分前和划分后的泛化性能进行估计。划分后的验证集精度如果比划分前的验证集精度高，那么，就决定划分，否则，预剪枝策略禁止这个结点被划分。

优点：预剪枝使得决策树的很多分支都没有展开，这不仅降低来过拟合的风险，还显著减少了决策树的训练时间开销和测试时间的开销。

缺点：预剪枝基于“贪心”的本质，禁止这些分支展开，给预剪枝决策树带来来欠拟合的风险。

- 后剪枝

后剪枝策略通常比预剪枝策略保留更多的分支。一般情况下，后剪枝决策树的欠拟合风险很小，泛化能力往往优于预剪枝决策树，但是它的训练时间开销比未剪枝决策树和预剪枝决策树都要大的多。
